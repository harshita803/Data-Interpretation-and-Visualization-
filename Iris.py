# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GGg0ZPMALRxSThyfLth4ljJiEulf6ZDw
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

iris = load_iris()
X = iris.data
y = iris.target
df = pd.DataFrame(X, columns=iris.feature_names)
df['species'] = iris.target_names[y]

print("First 5 rows of dataset:")
print(df.head())

plt.figure(figsize=(8,6))
sns.pairplot(df, hue="species", diag_kind="kde")
plt.show()

plt.figure(figsize=(6,4))
sns.heatmap(df.drop("species", axis=1).corr(), annot=True, cmap="coolwarm")
plt.title("Feature Correlation")
plt.show()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)


models = {
    "KNN": KNeighborsClassifier(n_neighbors=5),
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Logistic Regression": LogisticRegression(max_iter=200)
}

for name, model in models.items():
    if name in ["KNN", "Logistic Regression"]:
        model.fit(X_train_scaled, y_train)
        y_pred = model.predict(X_test_scaled)
    else:
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

    print(f"\n{name} Results:")
    print("Accuracy:", accuracy_score(y_test, y_pred))
    print(classification_report(y_test, y_pred, target_names=iris.target_names))

from matplotlib.colors import ListedColormap

def plot_decision_boundary(model, X, y, title):
    X = X[:, :2]  # only take first 2 features
    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    h = 0.02

    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                         np.arange(y_min, y_max, h))

    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)

    plt.figure(figsize=(6,4))
    plt.contourf(xx, yy, Z, alpha=0.3, cmap=ListedColormap(("red","green","blue")))
    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', cmap=ListedColormap(("red","green","blue")))
    plt.xlabel(iris.feature_names[0])
    plt.ylabel(iris.feature_names[1])
    plt.title(title)
    plt.show()

X_vis = X[:, :2]
X_train_v, X_test_v, y_train_v, y_test_v = train_test_split(X_vis, y, test_size=0.2, random_state=42, stratify=y)

tree_clf = DecisionTreeClassifier(random_state=42)
tree_clf.fit(X_train_v, y_train_v)
plot_decision_boundary(tree_clf, X_vis, y, "Decision Boundary - Decision Tree")

knn_clf = KNeighborsClassifier(n_neighbors=5)
knn_clf.fit(X_train_v, y_train_v)
plot_decision_boundary(knn_clf, X_vis, y, "Decision Boundary - KNN")

log_clf = LogisticRegression(max_iter=200)
log_clf.fit(X_train_v, y_train_v)
plot_decision_boundary(log_clf, X_vis, y, "Decision Boundary - Logistic Regression")

plt.figure(figsize=(10,6))
plot_tree(tree_clf, filled=True, feature_names=iris.feature_names[:2], class_names=iris.target_names)
plt.show()